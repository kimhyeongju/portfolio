from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
import os
import traceback

# OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì— ë”°ë¥¸ import
try:
    from openai import OpenAI  # ìƒˆ ë²„ì „ (1.x)
    NEW_OPENAI = True
    logger = logging.getLogger(__name__)
    logger.info("ìƒˆ ë²„ì „ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© (1.x)")
except ImportError:
    import openai  # êµ¬ ë²„ì „ (0.x)
    NEW_OPENAI = False
    logger = logging.getLogger(__name__)
    logger.info("êµ¬ ë²„ì „ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© (0.x)")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# OpenAI API í‚¤ ì„¤ì •
api_key = os.getenv('OPENAI_API_KEY')
logger.info(f"í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY: {'ì„¤ì •ë¨' if api_key else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")

if api_key:
    logger.info(f"API í‚¤ ê¸¸ì´: {len(api_key)}")
    logger.info(f"API í‚¤ ì‹œì‘: {api_key[:15]}...")
    
    if NEW_OPENAI:
        # ìƒˆ ë²„ì „ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = OpenAI(api_key=api_key)
    else:
        # êµ¬ ë²„ì „ OpenAI ì„¤ì •
        openai.api_key = api_key
        client = None
else:
    client = None

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ê¹€í˜•ì£¼ë¼ëŠ” ì‚¬ëŒì— ëŒ€í•´ ì˜ ì•Œê³ ìˆìŠµë‹ˆë‹¤. ë‹µë³€ì€ ì œì‹œëœ ì •ë³´ì— ëŒ€í•œ ë‚´ìš© ë˜ëŠ” IT ê¸°ìˆ  ê´€ë ¨ ë‚´ìš©ì—ë§Œ ë‹µí•´ì£¼ì„¸ìš”. ê·¸ ì™¸ ì§ˆë¬¸ì—ëŠ” ì˜ ëª¨ë¥´ê² ë‹¤ê³  ê³µì†í•˜ê²Œ ë‹µí•˜ì„¸ìš”.

## ê¹€í˜•ì£¼ì˜ ì •ë³´:
- ì´ë¦„ì€ ê¹€í˜•ì£¼, ë‚˜ì´ëŠ” 94ë…„ 1ì›” ìƒ ë‚¨ì„±ì´ë©°, êµ°ëŒ€ëŠ” ì˜ê²½ ë§Œê¸°ì œëŒ€ í•¨.
- ê³ ë“±í•™êµëŠ” ì¤‘êµ­ ì²œì§„ê³¼ ë¶ê²½ì—ì„œ ë‹¤ë…”ìœ¼ë©°, í•™ë¶€ëŠ” ê°€ì²œëŒ€í•™êµ ê²½ì œí•™ê³¼ ì£¼ì „ê³µ, ë¬¼ë¦¬í•™ê³¼ ë³µìˆ˜ì „ê³µ í•¨. ì„ì‚¬ëŠ” ê´‘ì£¼ê³¼í•™ê¸°ìˆ ì›(GIST)ì—ì„œ ì „ê¸°ì „ìì»´í“¨í„°ê³µí•™ë¶€ ì¡¸ì—….
- ì„ì‚¬ ì—°êµ¬ ì£¼ì œëŠ” ì–‘ìë‚´ì„± ì „ìì„œëª… ì•Œê³ ë¦¬ì¦˜ê³¼ ë¸”ë¡ì²´ì¸ í•©ì˜ì²´ êµ¬ì„± ì•Œê³ ë¦¬ì¦˜ì— ê´€í•œ ì—°êµ¬.
- í•œêµ­ì „ìí†µì‹ ì—°êµ¬ì›(ETRI) ìœ„ì´‰ì—°êµ¬ì› ê²½í—˜ : NISTì—ì„œ ì§„í–‰ì¤‘ì¸ ì–‘ìë‚´ì„± ì•”í˜¸ ê³µëª¨ì— ëŒ€í•œ ì„¸ë¯¸ë‚˜ ì§„í–‰ ë° ë¸”ë¡ì²´ì¸ ì§€ê°‘ ë³´ì•ˆì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ë² ë“œ êµ¬ì¶•.
- Spring Boot Backend ê°œë°œ ì¸í„´ ê²½í—˜ : ì†”íŠ¸ë£©ìŠ¤ íšŒì‚¬ì˜ ìƒì„±í˜• AI ë¶€ì„œì—ì„œ ë²•ë¥  ë³´ì¡° ì„œë¹„ìŠ¤ ì±—ë´‡ ë°±ì—”ë“œ ê°œë°œ ì°¸ì—¬. ì£¼ë¡œ ì‚¬ìš©ì ê´€ë¦¬ ë° ë¬¸ì„œ ì‘ì„± í…œí”Œë¦¿ ë“±ì˜ ì„œë¹„ìŠ¤ ê°œë°œ.
- êµìœ¡ ê²½í—˜ : 2025ë…„ 2ì›”ë¶€í„° 6ê°œì›”ê°„ í´ë¼ìš°ë“œ, ë„¤íŠ¸ì›Œí¬, ë¦¬ëˆ…ìŠ¤ ì„œë²„ êµ¬ì¶• êµìœ¡ì„ ìˆ˜ê°•. ë˜í•œ 2024ë…„ 3ì›”ë¶€í„° 6ê°œì›”ê°„ java, spring framework(spring boot), Database, ë¨¸ì‹ ëŸ¬ë‹, ì¸ê³µì§€ëŠ¥ êµìœ¡ ìˆ˜ê°•. 
- ê°€ìƒí™” ê¸°ìˆ  : Docker ì´ë¯¸ì§€ ìƒì„± ë° docker hubì— ë°°í¬ ì‹¤ìŠµ. vagrantë¡œ Kubernetes í´ëŸ¬ìŠ¤í„° êµ¬ì¶• ì‹¤ìŠµ.
- AWS í´ë¼ìš°ë“œ :  EC2ë¡œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë§Œë“¤ê³ , Route53ì—ì„œ ë„ë©”ì¸ ë° ì¸ì¦ì„œ ìƒì„±. ë¡œë“œë°¸ëœì„œ, ë³´ì•ˆ ê·¸ë£¹ ë“±ì„ ë§Œë“¤ì–´ì„œ https ë„ë©”ì¸ ë³´ì•ˆ ì—°ê²° êµ¬ì¶•.
- CI êµ¬ì¶• : Git actionìœ¼ë¡œ deví™˜ê²½ì—ì„œ ì½”ë“œ pushí•˜ë©´ ìë™ìœ¼ë¡œ aws ec2 í™˜ê²½ì— ë°°í¬ (í¬íŠ¸í´ë¦¬ì˜¤ ì›¹ì‚¬ì´íŠ¸ ê°œë°œ).
- í”„ë¡œì íŠ¸ : RAGë¥¼ í™œìš©í•˜ì—¬ ì²­ë…„ ì •ì±…ì— ëŒ€í•œ ì§ˆì˜ì‘ë‹µì„ í•´ì£¼ëŠ” ì±—ë´‡ ì„œë¹„ìŠ¤ ì™¸ 3ê°œì˜ í”„ë¡œì íŠ¸ ìˆìŒ(project í•­ëª© ì°¸ê³ ).
- ë„¤íŠ¸ì›Œí¬ ì§€ì‹ : Cisco Packet tracerë¥¼ ì´ìš©í•œ ë„¤íŠ¸ì›Œí¬ í† í´ë¡œì§€ êµ¬ì¶• ì‹¤ìŠµí•´ë´„. ì—¬ëŸ¬ ë„¤íŠ¸ì›Œí¬ í”„ë¡œí† ì½œê³¼ OSIê³„ì¸µì— ëŒ€í•œ ì§€ì‹ ë³´ìœ .
- ë¦¬ëˆ…ìŠ¤ : ë³´ì•ˆ ì§€ì‹ê³¼, proxy, dhcp, log, SMTP, ë°±ì—… ë“± ì—¬ëŸ¬ ì„œë¹„ìŠ¤ë¥¼ êµ¬ì¶•í•´ë´„(project í•­ëª© ì°¸ê³ )

## ì—­í• :
1. ì£¼ì–´ì§„ ì •ë³´ì´ì™¸ì— ì ˆëŒ€ë¡œ ì„ì˜ë¡œ ë§Œë“¤ì–´ ë‚´ì§€ ì•ŠìŒ
2. IT ê¸°ìˆ  ê´€ë ¨ ì§ˆë¬¸ ë‹µë³€
3. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ì‘ë‹µ
4. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì œê³µí•˜ë©° 200ê¸€ìë¥¼ ë„˜ì§€ ì•ŠìŒ

"""

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        "status": "healthy",
        "openai_configured": bool(api_key),
        "openai_version": "1.x" if NEW_OPENAI else "0.x"
    }), 200

@app.route('/chat', methods=['POST'])
def chat():
    try:
        logger.info("=== ì±„íŒ… ìš”ì²­ ì‹œì‘ ===")
        
        # ìš”ì²­ ë°ì´í„° í™•ì¸
        data = request.get_json()
        logger.info(f"ë°›ì€ ë°ì´í„°: {data}")
        
        if not data or 'message' not in data:
            logger.error("ë©”ì‹œì§€ê°€ ì—†ìŒ")
            return jsonify({"error": "ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400
        
        user_message = data['message']
        logger.info(f"ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}")
        
        # API í‚¤ í™•ì¸
        if not api_key:
            logger.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return jsonify({
                "response": "ì•ˆë…•í•˜ì„¸ìš”! í˜„ì¬ AI ì„œë¹„ìŠ¤ ì„¤ì • ì¤‘ì…ë‹ˆë‹¤. ê³§ ì •ìƒì ì¸ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆì„ ì˜ˆì •ì…ë‹ˆë‹¤. ğŸ˜Š",
                "status": "success"
            }), 200
        
        # OpenAI API í˜¸ì¶œ
        logger.info("OpenAI API í˜¸ì¶œ ì‹œì‘")
        
        try:
            if NEW_OPENAI and client:
                # ìƒˆ ë²„ì „ API í˜¸ì¶œ
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": user_message}
                    ],
                    max_tokens=500,
                    temperature=0.7
                )
                ai_response = response.choices[0].message.content
                
            else:
                # êµ¬ ë²„ì „ API í˜¸ì¶œ
                response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": SYSTEM_PROMPT},
                        {"role": "user", "content": user_message}
                    ],
                    max_tokens=500,
                    temperature=0.7
                )
                ai_response = response.choices[0].message.content
                
            logger.info("OpenAI API í˜¸ì¶œ ì„±ê³µ")
            logger.info(f"AI ì‘ë‹µ: {ai_response[:100]}...")
            
            return jsonify({
                "response": ai_response,
                "status": "success"
            }), 200
            
        except Exception as openai_error:
            logger.error(f"OpenAI API ì—ëŸ¬: {str(openai_error)}")
            logger.error(f"OpenAI ì—ëŸ¬ íƒ€ì…: {type(openai_error)}")
            
            # ì‚¬ìš©ìì—ê²Œ ì¹œê·¼í•œ ì—ëŸ¬ ë©”ì‹œì§€
            return jsonify({
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. ğŸ¤–",
                "status": "success"  # ì‚¬ìš©ìì—ê²ŒëŠ” ì„±ê³µìœ¼ë¡œ í‘œì‹œ
            }), 200
            
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {str(e)}")
        logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        
        return jsonify({
            "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
            "status": "success"  # ì‚¬ìš©ìì—ê²ŒëŠ” ì„±ê³µìœ¼ë¡œ í‘œì‹œ
        }), 200

@app.route('/test', methods=['GET'])
def test():
    return jsonify({
        "message": "Flask APIê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤!",
        "openai_configured": bool(api_key),
        "openai_version": "1.x" if NEW_OPENAI else "0.x"
    }), 200

if __name__ == '__main__':
    logger.info("=== Flask ì•± ì‹œì‘ ===")
    logger.info(f"OpenAI ë²„ì „: {'1.x (ìƒˆ ë²„ì „)' if NEW_OPENAI else '0.x (êµ¬ ë²„ì „)'}")
    logger.info(f"í™˜ê²½ë³€ìˆ˜ ìƒíƒœ: OPENAI_API_KEY = {'ì„¤ì •ë¨' if api_key else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
    app.run(host='0.0.0.0', port=5000, debug=True)